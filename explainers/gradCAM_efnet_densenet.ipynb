{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the folder with chexpert dataset which has structure outline in the project description\n",
    "data_path = '/data'\n",
    "\n",
    "train_csv_path = data_path + '/chexpert/v1.0/train.csv'\n",
    "valid_csv_path = data_path + '/chexpert/v1.0/valid.csv'\n",
    "dir_path = data_path + '/chexpert/v1.0/'\n",
    "\n",
    "#path to the directory with saved state dictionaries\n",
    "model_save_dir = '/saves'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that drops lateral image records and irrelevant columns and edits the \"Path\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropper(df):\n",
    "    d = df.copy()\n",
    "    index = d[d[\"Frontal/Lateral\"] == \"Lateral\"].index\n",
    "    d.drop(index=index, axis=0, inplace=True)\n",
    "    d = d.drop(columns=['Sex','Age','Frontal/Lateral','AP/PA'])\n",
    "    d.Path = d.Path.str.replace('CheXpert-','chexpert/')\n",
    "    d = d.reset_index(drop=True)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_csv = pd.read_csv(valid_csv_path, sep=',').fillna(0)\n",
    "dval = dropper(valid_csv)\n",
    "\n",
    "train_csv = pd.read_csv(train_csv_path, sep=',').fillna(0)\n",
    "dtrain = dropper(train_csv)\n",
    "\n",
    "# image paths as Series\n",
    "vpath = dval.Path\n",
    "tpath = dtrain.Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet transform\n",
    "efnet_transform = transforms.Compose([\n",
    "    transforms.Resize((456, 456)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# densenet transform\n",
    "dnet_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that receives a binary vector and outputs 1d array with indexes of elements which are ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findings(z, beta=0.5):\n",
    "\n",
    "    # assume z is a tensor \n",
    "    if type(z) != np.ndarray:\n",
    "        y = z.squeeze().numpy()\n",
    "        #print('shape',y.shape)\n",
    "    else:\n",
    "        y = z.copy().squeeze()\n",
    "        #print(y)\n",
    "\n",
    "    idx = np.argwhere(y > beta)\n",
    "\n",
    "    if idx.ndim > 1:\n",
    "        idx = idx.squeeze()\n",
    "\n",
    "    if idx.ndim == 0:\n",
    "        idx = np.expand_dims(idx,0)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for gradCAM to work, one has to store feature maps during forward pass and their gradients during backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradients for gradcam are stored here\n",
    "stored_grads = torch.Tensor([])\n",
    "stored_fpass = torch.Tensor([])\n",
    "\n",
    "def bpass_hook(self, gin, gout):\n",
    "    global stored_grads\n",
    "    stored_grads = gout\n",
    "\n",
    "def fpass_hook(self, ten_in, ten_out):\n",
    "    global stored_fpass\n",
    "    stored_fpass = ten_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(n=0):\n",
    "    global model, transform\n",
    "    \n",
    "    if n==0:\n",
    "        # Load the DenseNet121 \n",
    "        model = torchvision.models.densenet121()\n",
    "        # Get the input dimension of last layer\n",
    "        kernel_count = model.classifier.in_features\n",
    "        # Replace last layer with new layer that have num_classes nodes, after that apply Sigmoid to the output\n",
    "        model.classifier = nn.Sequential(nn.Linear(kernel_count, 14), nn.Sigmoid())\n",
    "        \n",
    "        name = 'epoch_1_score_0.81652.pth'\n",
    "        model.load_state_dict(torch.load(os.path.join(model_save_dir, name))['state_dict'])\n",
    "        _=model.eval()\n",
    "        \n",
    "        # Get module object of last conv layer to attach hook to it\n",
    "        last_conv_layer = model.net.features.denseblock4.denselayer16.conv2\n",
    "        transform = dnet_transform\n",
    "\n",
    "    if n==1:\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b5')\n",
    "        model = nn.Sequential(nn.Linear(2048, 14), nn.Sigmoid())\n",
    "        \n",
    "        loaded_tuple = torch.load(model_save_dir+'epoch_3_score_0.88577.pth', map_location='cpu')\n",
    "        state_dict = loaded_tuple['state_dict']\n",
    "\n",
    "        # rename keys of state dict for efficient net\n",
    "        keys = list(state_dict.keys())\n",
    "        for k in keys:\n",
    "            new_key = k[4:]\n",
    "            state_dict[new_key] = state_dict.pop(k)\n",
    "        \n",
    "        model.load_state_dict(state_dict)\n",
    "        _ = model.eval()\n",
    "        \n",
    "        last_conv_layer = model.net._conv_head\n",
    "        transform = efnet_transform\n",
    "    \n",
    "    # register hooks for gradCAM\n",
    "    handle_b = last_conv_layer.register_backward_hook(bpass_hook)\n",
    "    handle_f = last_conv_layer.register_forward_hook(fpass_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch random image and extract true labels and \"uncertain\" labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image and true labels\n",
    "imid = np.random.randint(dtrain.shape[0])\n",
    "print(imid)\n",
    "path1 = data_path+dtrain.Path[imid]\n",
    "\n",
    "image_orig = Image.open(path1).convert('RGB')\n",
    "image_transformed = transform(image_orig).unsqueeze(0)\n",
    "\n",
    "true_labels_vec = dtrain.iloc[imid,1:].to_numpy().astype(int)\n",
    "true_labels = np.argwhere(true_labels_vec==1).flatten()\n",
    "true_labels_uncertain = np.argwhere((-1)*true_labels_vec==1).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run gradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run model\n",
    "out = model(image_transformed)\n",
    "out_np = out.detach().numpy().squeeze()\n",
    "\n",
    "pred_labels_binary = findings(out_np)\n",
    "pred_labels_p = np.round(out_np[pred_labels_binary], 2)\n",
    "\n",
    "# generate arguments for backward() function corresponding to classes with p>0.5\n",
    "l = len(pred_labels_binary)\n",
    "args = []\n",
    "for ii in pred_labels_binary:\n",
    "    backward_arg = torch.zeros(1,14)\n",
    "    backward_arg[0,ii] = 1\n",
    "    args.append(backward_arg)\n",
    "    \n",
    "# generate gradCAMs\n",
    "hmap_list = []\n",
    "cam_list = []\n",
    "\n",
    "img_hmap = np.transpose(image_transformed.squeeze().numpy(),(1,2,0))\n",
    "\n",
    "# plot\n",
    "arglen = len(args)\n",
    "kwargs = dict(xticks=[],yticks=[])\n",
    "\n",
    "fig, ax = plt.subplots(1, arglen, figsize=(5*arglen,5), subplot_kw=kwargs)\n",
    "if arglen==1:\n",
    "    ax = [ax]\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "\n",
    "for k, a in enumerate(args):\n",
    "    print('{}/{}'.format(k+1,arglen))\n",
    "    out.backward(a, retain_graph=True)\n",
    "\n",
    "    gradients = stored_grads[0].clone()\n",
    "    activations = stored_fpass[0].clone().unsqueeze(0)\n",
    "    activations = activations.detach()\n",
    "\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "    for j in range(gradients.shape[1]):\n",
    "        activations[:, j, :, :] *= pooled_gradients[j]\n",
    "\n",
    "    heatmap = torch.sum(activations, dim=1).squeeze()\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= torch.max(heatmap)\n",
    "\n",
    "    hmap_list.append(heatmap)\n",
    "    \n",
    "    #ax.flatten()[k].imshow(heatmap)\n",
    "    \n",
    "\n",
    "    hmap = heatmap.numpy()\n",
    "    heatmap1 = cv2.resize(hmap, (img_hmap.shape[1], img_hmap.shape[0]))\n",
    "    heatmap1 = np.uint8(-255 * heatmap1 + 255)\n",
    "    heatmap1 = cv2.applyColorMap(heatmap1, cv2.COLORMAP_JET)\n",
    "\n",
    "    supim = heatmap1 * 0.002 + img_hmap\n",
    "    supim = supim / supim.max()\n",
    "    \n",
    "    cam_list.append(supim)\n",
    "    \n",
    "    ax[k].imshow(supim)\n",
    "    ax[k].set_title(dtrain.columns[1:][pred_labels_binary[k]])\n",
    "\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print('True labels:', true_labels, dtrain.columns[1:][true_labels].to_list())\n",
    "print('Uncertainties:', true_labels_uncertain, dtrain.columns[1:][true_labels_uncertain].to_list())\n",
    "print('Prediction:', pred_labels_binary, dtrain.columns[1:][pred_labels_binary].to_list())\n",
    "print('Probabilities:', pred_labels_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
